{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind_from_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data from excel into dataframe\n",
    "df=pd.read_excel('OaO data modified.xlsx',header=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plan going forward:\n",
    "1. Get all means for each make (already done)\n",
    "2. choose categorical vars to slice by\n",
    "3. get all means for each make when sliced by categorical vars\n",
    "4. perform ttest and sample size filter to determine validity\n",
    "5. put results in table, perform hierarchical clustering\n",
    "\n",
    "[var1, var2, mean, stDev, count1, count2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catList = ['Age Bucket','Education - Principal Driver','Household Income','Intention Vehicle - Make','Principal Driver - Marital Status','Principal Driver - Sex','Purch Veh From Company Origin: Germany','Purch Veh From Company Origin: Japan','Purch Veh From Company Origin: Korea','Purch Veh From Company Origin: U.S.','Race Code (1)','Replaced Vehicle','State','Familiar With Categorical']\n",
    "makeList=['Acura','Audi','BMW','Buick','Cadillac','Chevrolet','Chrysler','Dodge','Ford','GMC','Honda','Hyundai','Infiniti','Jeep','Kia','Lexus','Lincoln','Mazda','Mercedes-Benz','MINI','Mitsubishi','Nissan','RAM','Subaru','Tesla','Toyota','Volkswagen','Volvo']\n",
    "optionExcludeList=['Kansas','Louisiana','Oklahoma','Arkansas','New Hampshire','Maine','New Mexico','Idaho','Mississippi','Rhode Island','West Virginia','Delaware','Nebraska','District Of Columbia','Montana','South Dakota','Vermont','North Dakota','Lincoln','Volvo','Infiniti','Mitsubishi','Mini','Land Rover','Fiat','Jaguar','Scion','Porsche','Mercury','Suzuki','American','RAM','Chevy','Bentley','Eagle','Daewoo','smart','Isuzu','Maserati','Alfa','Daihatsu','Ferrari','Aston','Peugeot','Oldsmobile','Plymouth','Mercedes-Benz','Saturn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Bucket\n",
      "Education - Principal Driver\n",
      "Household Income\n",
      "Intention Vehicle - Make\n",
      "Principal Driver - Marital Status\n",
      "Principal Driver - Sex\n",
      "Purch Veh From Company Origin: Germany\n",
      "Purch Veh From Company Origin: Japan\n",
      "Purch Veh From Company Origin: Korea\n",
      "Purch Veh From Company Origin: U.S.\n",
      "Race Code (1)\n",
      "Replaced Vehicle\n",
      "State\n",
      "Familiar With Categorical\n"
     ]
    }
   ],
   "source": [
    "#initialize dfFull dict with full dataset\n",
    "dfFull = {'Full': df.describe().T.drop(['min','25%','50%','75%','max'], axis=1)}\n",
    "\n",
    "#add each subgroup dataframe to dfFull dict under subcategory key\n",
    "for subset in catList:\n",
    "    print(subset)\n",
    "    if subset=='Familiar With Categorical':\n",
    "        for make in makeList:\n",
    "            for option in df[make,subset].dropna().unique():\n",
    "                test=df[df[make,subset]==option].describe().T.drop(['min','25%','50%','75%','max'], axis=1)\n",
    "                dfFull[make+'_'+subset+'_'+option]=test\n",
    "    else:\n",
    "        for option in df['Demographic',subset].dropna().unique():\n",
    "            if option not in optionExcludeList:\n",
    "                test=df[df['Demographic',subset]==option].describe().T.drop(['min','25%','50%','75%','max'], axis=1)\n",
    "                dfFull[subset+'_'+option]=test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in dfFull.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:875: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "D:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:875: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "D:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1814: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "#iterate through each possible dataframe, concatenate new ttest frame to dfTest\n",
    "import itertools\n",
    "keyList=list(dfFull.keys())\n",
    "dfTest=pd.DataFrame(index=dfFull['Full'].index, columns=['subset1', 'subset2', 'avg1', 'avg2', 'significance', 'likelyhood','count1', 'count2'])\n",
    "for subset1,subset2 in itertools.combinations(keyList,2):\n",
    "    temp=pd.DataFrame(index=dfFull['Full'].index, columns=['subset1', 'subset2', 'avg1', 'avg2', 'significance', 'likelyhood','count1', 'count2'])\n",
    "    temp['subset1']=subset1\n",
    "    temp['subset2']=subset2\n",
    "    temp['avg1']=dfFull[subset1]['mean'].values\n",
    "    temp['avg2']=dfFull[subset2]['mean'].values\n",
    "    t,p=ttest_ind_from_stats(dfFull[subset1]['mean'],dfFull[subset1]['std'],dfFull[subset1]['count'],dfFull[subset2]['mean'],dfFull[subset2]['std'],dfFull[subset2]['count'],equal_var=False)\n",
    "    temp['significance']=t\n",
    "    temp['likelyhood']=p\n",
    "    temp['count1']=dfFull[subset1]['count']\n",
    "    temp['count2']=dfFull[subset2]['count']\n",
    "    temp=temp[temp['count1']>30]\n",
    "    temp=temp[temp['count2']>30]\n",
    "    dfTest=pd.concat([dfTest,temp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfSignificant=dfTest[dfTest['likelyhood']<.050001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfSignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfSignificant.to_excel(\"significant.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
